{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "ROOT_PATH = os.path.normpath(os.path.join(os.getcwd(), os.pardir))\n",
    "ROOT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data = pd.read_csv(\"/content/drive/MyDrive/data.csv\")\n",
    "except:\n",
    "    data = pd.read_csv(os.path.join(ROOT_PATH, \"data\", \"data.csv\"))\n",
    "# Load the data\n",
    "\n",
    "print(\"Shape of data {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into array\n",
    "data = np.array(data)\n",
    "\n",
    "# Split into samples and labels (X and Y)\n",
    "X = data[:, 1:]\n",
    "X = X.T\n",
    "\n",
    "Y = data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splits(X, Y, N_train):\n",
    "    N = X.shape[1]\n",
    "\n",
    "    # getting an array with indeces from 0 to N-1\n",
    "    indeces = np.arange(N)\n",
    "    # shuffling randomly\n",
    "    np.random.shuffle(indeces)\n",
    "\n",
    "    # get the first N_train for the train split (but now they are random)\n",
    "    train_idx = indeces[:N_train]\n",
    "    # the rest are for test split\n",
    "    test_idx = indeces[N_train:]\n",
    "\n",
    "    # slice the original datasets with an index array\n",
    "    X_train = X[:, train_idx]  \n",
    "    Y_train = Y[train_idx]\n",
    "    \n",
    "    X_test = X[:, test_idx]\n",
    "    Y_test = Y[test_idx]\n",
    "\n",
    "    # put in tuples the two splits\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "\n",
    "def get_data_from_index(X, Y, indexes):\n",
    "    \n",
    "    # start from empty lists for both samples and labels\n",
    "    final_X = []\n",
    "    final_Y = []\n",
    "\n",
    "    # for each chosen label\n",
    "    for k in indexes:\n",
    "        # find which samples have label=k\n",
    "        idxs_k = (Y == k)\n",
    "        # slice the samples and append them to a list\n",
    "        final_X.append( X[:, idxs_k] )\n",
    "        # same thing to the labels\n",
    "        final_Y.append( Y[idxs_k] )\n",
    "\n",
    "    # concatenate together all the previous iterations\n",
    "    X = np.concatenate(final_X, axis=1)\n",
    "    Y = np.concatenate(final_Y)\n",
    "\n",
    "    # return the new dataset and labels\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% to train, the rest to test\n",
    "train_split = 0.8\n",
    "N_train = round(X.shape[1]*train_split)\n",
    "\n",
    "# get the train and test splits both for samples and for lables\n",
    "(X_train, Y_train), (X_test, Y_test) = data_splits(X, Y, N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose digits\n",
    "indeces = [0, 6]\n",
    "X_train, Y_train = get_data_from_index(X_train, Y_train, indeces)\n",
    "X_test, Y_test = get_data_from_index(X_test, Y_test, indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(loss, grad_l, w0, data, batch_size, n_epochs):\n",
    "    alpha = 1e-3\n",
    "    X, Y = data\n",
    "\n",
    "    w = [w0]\n",
    "    loss_val = []\n",
    "    grads_val = []\n",
    "    err_val = []\n",
    "\n",
    "    k=0\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch_X = X[i:i+batch_size]\n",
    "            batch_Y = Y[i:i+batch_size]\n",
    "            w.append(w[k] - alpha*grad_l(batch_X, batch_Y, w0))\n",
    "            k += 1\n",
    "\n",
    "        loss_val.append(loss(w[-1], X, Y))\n",
    "        grads_val.append(grad_l(w[-1], X, Y))\n",
    "        err_val.append(np.linalg.norm(grads_val[-1])**2)\n",
    "        \n",
    "        \n",
    "    return w, loss_val, grads_val, err_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e027379c6121b5e6bf64ed9100277294218b9e98ce7db2c95bb2476df4c3fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
